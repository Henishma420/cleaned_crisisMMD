# cleaned_crisisMMD
Worked on the popular CrisisMMD dataset and processed it for a multi-modal classification task involving both text and image data. 

Preprocessing of the CrisisMMD Dataset for Multi-Modal Classification

The CrisisMMD dataset, which is a well-known benchmark for crisis-related multi-modal classification tasks, includes both text and image data collected from social media (primarily Twitter) during real-world disasters. The core objective of this dataset is to support the development of AI models that can automatically classify content as informative or non-informative, and further categorize informative content into one of several disaster-related categories. 

For my project, I have extensively cleaned and processed the dataset to prepare it for multi-modal machine learning models. The dataset includes a total of 18,082 tweets, each associated with both text and image data. Each tweet is uniquely identified by a tweet_id field, ranging from 0 to 18,081 in the corresponding CSV file.

Text Preprocessing

Each tweetâ€™s text was preprocessed using standard Natural Language Processing (NLP) techniques. I used a transformer-based tokenizer (such as BERT) to tokenize the text data. The output for each tweet includes:

Input IDs: Tokenized representation of the tweet suitable for transformer models.
Attention Masks: Binary masks indicating which tokens are actual input tokens and which are padding.
Label Text: A binary classification label indicating whether the tweet is informative (1) or non-informative (0).

Image Preprocessing

The associated image for each tweet was passed through a pre-trained ResNet model to extract high-level visual features. The resulting image embeddings have been flattened and stored across columns 0 to 2047, yielding 2048-dimensional image feature vectors for each image.

In addition to the extracted features, a label for the image (similar to the text) was also assigned, indicating whether the visual content is informative (1) or non-informative (0). This is stored in a separate field called label_image.

Disaster Type Labeling

For the informative samples, each tweet has been further annotated with a fine-grained disaster type label ranging from 0 to 6. These correspond to distinct disaster categories such as earthquakes, floods, wildfires, etc., enabling more granular classification tasks.

Final Dataset Overview

Column/Feature	Description

tweet_id	Unique ID for each tweet (0 to 18,081)
text	Raw tweet text
input_ids	Token IDs generated by the tokenizer
attention_mask	Binary attention mask for padding
label_text	Informative (1) or Non-informative (0)
disaster_label	Disaster category label (0 to 6)
image_feature_0 to image_feature_2047	ResNet-extracted image features (2048-dim)
label_image	Informative (1) or Non-informative (0) for image

This processed dataset is now fully ready to be used for training advanced multi-modal deep learning models, combining both textual and visual inputs to improve crisis detection and classification tasks during emergencies.
